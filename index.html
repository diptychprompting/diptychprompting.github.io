<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>DiptychPrompting</title>
<link href="./DiptychPrompting_files/style.css" rel="stylesheet">
<script type="text/javascript" src="./DiptychPrompting_files/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./DiptychPrompting_files/jquery.js"></script>
</head>

<body>
<div class="content">
  <h1><strong>Large-Scale Text-to-Image Model with Inpainting is a Zero-Shot Subject-Driven Image Generator</strong></h1>
  <!-- <p id="authors"><span></span><a href="">Chaehun Shin<sup>1</sup></a> <a href="">Jooyoung Choi<sup>1</sup></a> <a href="">Heeseung Kim<sup>1</sup></a> <a href="">Sungroh Yoon<sup>1,2,*</sup></a>  <br> -->
  <p id="authors"><span></span><a href="https://scholar.google.com/citations?user=M8RX0MEAAAAJ&hl=en&oi=ao">Chaehun Shin<sup>1</sup></a> <a href="https://scholar.google.com/citations?user=9EIn52wAAAAJ&hl=en&oi=ao">Jooyoung Choi<sup>1</sup></a> <a href="https://gmltmd789.github.io">Heeseung Kim<sup>1</sup></a> <a href="https://scholar.google.com/citations?user=Bphl_fIAAAAJ&hl=en">Sungroh Yoon<sup>1,2,*</sup></a>  <br>
  <span style="font-size: 16px"><br>
    <sup>1</sup> Data Science and AI Laboratory, ECE, Seoul National University <br>
    <sup>2</sup> AIIS, ASRI, INMC, ISRC, and Interdisciplinary Program in AI, Seoul National University <br>
  <sup>*</sup> Corresponding author
    </p>
  </span></p>
  <br>
  <img src="./DiptychPrompting_files/teaser.png" class="teaser-gif" style="width:100%;"><br>
  <h3 style="text-align:center"><em>Diptych Prompting reinterprets the zero-shot subject-driven text-to-image generation as an inpainting task!</em></h3>
    <font size="+2">
          <p style="text-align: center;">
            <!-- <a href="" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp; -->
	          <!-- <a href="" target="_blank">[Code](coming sooon)</a> &nbsp;&nbsp;&nbsp;&nbsp; -->
            <!-- <a href="" target="_blank">[BibTeX]</a> -->
            <a href="https://arxiv.org/abs/2411.15466" target="_blank">[Paper]</a>  &nbsp;&nbsp;&nbsp;&nbsp;
            <!-- <a>[Code]</a>  &nbsp;&nbsp;&nbsp;&nbsp; -->
            <a>[Code]</a>(<font color="#C70039">Coming Soon!</font>)&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="DiptychPrompting_files/bibtex.txt" target="_blank">[BibTeX]</a>
          </p>
    </font>
</div>
<div class="content">
  <h2 style="text-align:center;">Abstract</h2>
  <p>Subject-driven text-to-image generation aims to produce images of a new subject within a desired context by accurately capturing both the visual characteristics of the subject and the semantic content of a text prompt. Traditional methods rely on time- and resource-intensive fine-tuning for subject alignment, while recent zero-shot approaches leverage on-the-fly image prompting, often sacrificing subject alignment. In this paper, we introduce Diptych Prompting, a novel zero-shot approach that reinterprets as an inpainting task with precise subject alignment by leveraging the emergent property of diptych generation in large-scale text-to-image models. Diptych Prompting arranges an incomplete diptych with the reference image in the left panel, and performs text-conditioned inpainting on the right panel. We further prevent unwanted content leakage by removing the background in the reference image and improve fine-grained details in the generated subject by enhancing attention weights between the panels during inpainting. Experimental results confirm that our approach significantly outperforms zero-shot image prompting methods, resulting in images that are visually preferred by users. Additionally, our method supports not only subject-driven generation but also stylized image generation and subject-driven image editing, demonstrating versatility across diverse image generation applications.</p>
</div>

<div class="content">
  <h2>Method</h2>
  <p> 
    A 'Diptych' is an art term referring to a two-paneled artwork in which two panels are displayed side by side, each containing interrelated content.  
    Given the reference subject image and target text prompt describing the desired context, our Diptych Prompting begins by composing the triplet: an incomplete diptych containing the reference subject image in the left panel, text prompt describing the diptych with target context, and the binary mask specifying the right panel as the inpainting target.
    Subsequently, the right panel is completed through text-conditioned inpainting, generating an image that incorporates both the target subject and desired context effectively.
    In the inpainting process, we remove the background from the reference image using Grounding DINO and SAM to isolate only the subject related information in the reference image. 
    Additionally, to preserve fine-grained details of the subject in the generated image, we enhance the reference attention by rescaling the attention weights between the right panel query and the left panel key.    
  </p>
  <br>
  <!-- <img class="summary-img" src="./DiptychPrompting_files/framework.png" style="width:90%;"> <br> -->
  <img class="summary-img" src="./DiptychPrompting_files/method.png" style="width:100%;"> <br>
  <!-- <p> Given </p> -->
</div>

<div class="content">
  <h2>Results</h2>
  <p> Our Diptych Prompting achieves high-quality subject-driven text-to-image generation, satisfying both subject alignment and text alignment in a zero-shot manner across diverse subjects and situations.</p>
<img class="summary-img" src="./DiptychPrompting_files/qual_result2.png" style="width:100%;">
</div>

<div class="content">
  <h2>Qualitative Comparisons</h2>
  <p> Despite using an inpainting approach without any specialized training for subject-driven text-to-image generation, Diptych Prompting significantly outperforms encoder-based zero-shot methods. Its superiority is evident in capturing the granular details of reference subjects, even in challenging examples with characteristic fine details, such as a ‘monster toy’ or ‘backpack’. </p>
<img class="summary-img" src="./DiptychPrompting_files/qual_comp.png" style="width:100%;">
</div>

<div class="content">
  <h2>Stylized Image Generation</h2>
  <p> Diptych Prompting can be extended to stylized image generation by using a style image as the reference. The generated images accurately reflect the stylistic features of the reference style image, such as color scheme, texture, and layout.</p>
<img class="summary-img" src="./DiptychPrompting_files/stylized_gen2.png" style="width:100%;">
</div>

<div class="content">
  <h2>Subject-Driven Image Editing</h2>
  <p> Diptych Prompting enables subject-driven image editing by placing the reference subject image on the left panel and the editing target image on the right panel of the incomplete diptych. By masking only the desired area in the right panel and applying diptych inpainting, the reference subject from the left panel is seamlessly generated in the masked region on the right panel. The edited images effectively preserve the unmasked areas while integrating the desired subject into the target region. </p>
<img class="summary-img" src="./DiptychPrompting_files/editing2.png" style="width:100%;">
</div>
<!-- <div class="content">
  <h2>Societal Impact</h2>
  <p>This project aims to provide users with an effective tool for synthesizing personal subjects (animals, objects) in different contexts. While general text-to-image models might be biased towards specific attributes when synthesizing images from text, our approach enables the user to get a better reconstruction of their desirable subjects. On contrary, malicious parties might try to use such images to mislead viewers. This is a common issue, existing in other generative models approaches or content manipulation techniques. Future research in generative modeling, and specifically of personalized generative priors, must continue investigating and revalidating these concerns.</p>
  <br>
</div> -->
<!-- <div class="content">
  <h2>BibTex</h2>
  <code> @article{ruiz2022dreambooth,<br>
  &nbsp;&nbsp;title={DreamBooth: Fine Tuning Text-to-image Diffusion Models for Subject-Driven Generation},<br>
  &nbsp;&nbsp;author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},<br>
  &nbsp;&nbsp;booktitle={arXiv preprint arxiv:2208.12242},<br>
  &nbsp;&nbsp;year={2022}<br>
  } </code> 
</div> -->

<br><br>
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <!-- <div class="content"> -->
      website template from <a href="https://dreambooth.github.io/" target="_blank">DreamBooth</a>
      <!-- </div> -->
    </div>
  </div>
</footer>
<br><br>

</body>
</html>
